{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0dac59",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883366c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get parent directory (Thesis-Edvin)\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f083d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from datasets import load_dataset\n",
    "from rag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c327f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwes = load_dataset(\"Eathus/cwe_view1000_list_gpt_few_cwe_desc_fix\", split=\"train\")\n",
    "cwes_df = cwes.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from the .pkl file\n",
    "cwes_df = pd.read_pickle(\"tmp/gpt_cwe_desc_few_df.pkl\")\n",
    "import json\n",
    "\n",
    "mask = cwes_df[\"gpt_cwe_description\"].str.contains(\n",
    "    r\"^\\{\\\"gpt_cwe_description\\\":\", na=False\n",
    ")\n",
    "cwes_df.loc[mask, \"gpt_cwe_description\"] = cwes_df.loc[\n",
    "    mask, \"gpt_cwe_description\"\n",
    "].apply(lambda x: json.loads(x)[\"gpt_cwe_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwes_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwes_df.gpt_cwe_description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9719bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from rag import *\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"tmp/view_CWE-1000_all_weaknesses.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "old_documents = [\n",
    "    create_ordered_cwe_document(weakness, old=True) for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "document_dict = {doc.metadata[\"CWE_ID\"]: doc for doc in old_documents}\n",
    "cwes_df[\"RAG_Doc\"] = cwes_df.apply(\n",
    "    lambda x: Document(\n",
    "        page_content=x.gpt_cwe_description,\n",
    "        metadata={\n",
    "            **document_dict[x.ID].metadata,  # Original metadata\n",
    "            \"Abstraction\": CWE_abstraction[x.Abstraction.upper()].value,  # New field\n",
    "            #\"Child_IDs\": x.Children.tolist(),  # New field\n",
    "        },\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=cwe.gpt_cwe_description,\n",
    "        metadata={\n",
    "            **document_dict[cwe.ID].metadata,  # Original metadata\n",
    "            \"Abstraction\": CWE_abstraction[cwe.Abstraction.upper()].value,  # New field\n",
    "            #\"Child_IDs\": cwe.Children.tolist(),  # New field\n",
    "        },\n",
    "    )\n",
    "    for _, cwe in cwes_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e39d2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_norm_documents = [\n",
    "    create_ordered_cwe_document(weakness, CWE_doc_density.NORM, old=True)\n",
    "    for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "old_heavy_documents = [\n",
    "    create_ordered_cwe_document(weakness, CWE_doc_density.HEAVY, old=True)\n",
    "    for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "old_medium_documents = [\n",
    "    create_ordered_cwe_document(weakness, CWE_doc_density.MEDIUM, old=True)\n",
    "    for weakness in data[\"Weaknesses\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fa4b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_values = {\"Allowed\", \"Allowed-with-Review\", \"Discouraged\"}\n",
    "\n",
    "documents = [\n",
    "    doc for doc in documents if doc.metadata.get(\"MappingUsage\") in allowed_values\n",
    "]\n",
    "old_documents = [\n",
    "    doc for doc in old_documents if doc.metadata.get(\"MappingUsage\") in allowed_values\n",
    "]\n",
    "old_norm_documents = [\n",
    "    doc\n",
    "    for doc in old_norm_documents\n",
    "    if doc.metadata.get(\"MappingUsage\") in allowed_values\n",
    "]\n",
    "old_heavy_documents = [\n",
    "    doc\n",
    "    for doc in old_heavy_documents\n",
    "    if doc.metadata.get(\"MappingUsage\") in allowed_values\n",
    "]\n",
    "old_medium_documents = [\n",
    "    doc\n",
    "    for doc in old_medium_documents\n",
    "    if doc.metadata.get(\"MappingUsage\") in allowed_values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc3ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(old_norm_documents[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "63e4e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "\n",
    "def remove_subtitle(markdown_text, subtitle_names):\n",
    "    # Pattern to match the subtitle and all content until the next subtitle or end\n",
    "    ret = markdown_text\n",
    "    for name in subtitle_names:\n",
    "        pattern = r\"## \" + re.escape(name) + r\"\\b.*?(?=\\n## |\\Z)\"\n",
    "        ret = re.sub(pattern, \"\", ret, flags=re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    # Remove with flags for dot matching newline and case sensitivity\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_docs0 = [\n",
    "    Document(\n",
    "        page_content=cwe.page_content,\n",
    "        metadata=cwe.metadata,\n",
    "    )\n",
    "    for cwe in old_documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_docs1 = [\n",
    "    Document(\n",
    "        page_content=remove_subtitle(cwe.page_content, [\"Extended Description\"]),\n",
    "        metadata=cwe.metadata,\n",
    "    )\n",
    "    for cwe in old_documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_docs2 = [\n",
    "    Document(\n",
    "        page_content=remove_subtitle(\n",
    "            cwe.gpt_cwe_description, [\"Extended Description\", \"Demonstrative Scenario\"]\n",
    "        ),\n",
    "        metadata=document_dict[cwe.ID].metadata,\n",
    "    )\n",
    "    for _, cwe in cwes_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67182d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\n",
    "    (cwe, i)\n",
    "    for i, cwe in enumerate(bm25_docs1)\n",
    "    if cwe.page_content.rstrip() != bm25_docs2[i].page_content.rstrip()\n",
    "    and (\n",
    "        \"Extended Description\" not in old_documents[i].page_content\n",
    "        or \"Demonstrative Scenario\" not in old_documents[i].page_content\n",
    "    )\n",
    "]\n",
    "print(len(l))\n",
    "\n",
    "display(Markdown(bm25_docs1[l[0][1]].page_content))\n",
    "display(Markdown(bm25_docs2[l[0][1]].page_content))\n",
    "\n",
    "print(bm25_docs1[l[1][1]].page_content)\n",
    "print(bm25_docs2[l[1][1]].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df466c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(bm25_docs2[13].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056809f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds_view1000_complete = Dataset.from_pandas(cwes_df)\n",
    "ds_view1000_complete.push_to_hub(\"Eathus/cwe_view1000_list_rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "540a67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs(docs, echo=False):\n",
    "    all_docs = []\n",
    "    for doc in docs:\n",
    "        all_docs.extend(split_cwe_document(doc))\n",
    "    all_docs = add_sequential_ids(all_docs)\n",
    "    if echo:\n",
    "        print(f\"Original: {len(documents)} docs\")\n",
    "        print(f\"After splitting: {len(all_docs)} docs\")\n",
    "        # print(f\"Max tokens: {max(count_tokens(d.page_content) for d in all_docs)}\")\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c50c904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 881 docs\n",
      "After splitting: 900 docs\n"
     ]
    }
   ],
   "source": [
    "all_docs = split_docs(documents, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_old = split_docs(old_documents, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_bm25_0 = split_docs(bm25_docs0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_bm25_1 = split_docs(bm25_docs1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_bm25_2 = split_docs(bm25_docs2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f790c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_old_norm = split_docs(old_norm_documents, True)\n",
    "all_docs_old_heavy = split_docs(old_heavy_documents, True)\n",
    "all_docs_old_medium = split_docs(old_medium_documents, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9bf9ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new vector store...\n",
      "Vector store saved to tmp/faiss_gpt_index\n"
     ]
    }
   ],
   "source": [
    "vectorstore_gpt = create_vectorstore(all_docs, \"tmp/faiss_gpt_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_old = create_vectorstore(all_docs_old, \"tmp/faiss_old_index\")\n",
    "vectorstore_old_norm = create_vectorstore(all_docs_old_norm, \"tmp/faiss_old_norm_index\")\n",
    "vectorstore_old_heavy = create_vectorstore(\n",
    "    all_docs_old_heavy, \"tmp/faiss_old_heavy_index\"\n",
    ")\n",
    "vectorstore_old_medium = create_vectorstore(\n",
    "    all_docs_old_medium, \"tmp/faiss_old_medium_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test = load_dataset(\"Eathus/github-issues-vul-detection-xgb-results\", split='test')\n",
    "emb_test_df = test.to_pandas()\n",
    "print(len(emb_test_df))\n",
    "emb_test_df = emb_test_df[~emb_test_df.duplicated(subset=\"issue_github_id\", keep=False)]\n",
    "print(len(emb_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972d3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_few = load_dataset(\n",
    "    \"Eathus/github-issues-vul-detection-gpt-few-strict-vul-desc-results\", split=\"test\"\n",
    ")\n",
    "test_few_df = test_few.to_pandas()\n",
    "test_few_df = test_few_df[~test_few_df.duplicated(subset=\"issue_github_id\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fac201",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_few_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26636a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cip_pipeline_df = pd.merge(test_few_df, emb_test_df[['issue_github_id', 'xgb_prediction']], on='issue_github_id')\n",
    "cip_pipeline_df[\"cp_tf_label\"] = cip_pipeline_df.xgb_prediction&cip_pipeline_df.gpt_is_relevant\n",
    "cip_pipeline_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9183870",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_cp = cip_pipeline_df[cip_pipeline_df.cp_tf_label & ~cip_pipeline_df.cve_id.isna()]\n",
    "false_pos_cp = cip_pipeline_df[cip_pipeline_df.cp_tf_label & cip_pipeline_df.cve_id.isna()]\n",
    "false_neg_cp = cip_pipeline_df[~cip_pipeline_df.cp_tf_label & ~cip_pipeline_df.cve_id.isna()]\n",
    "all_true_cp = cip_pipeline_df[cip_pipeline_df.cp_tf_label]\n",
    "\n",
    "print(\"true pos:\", len(true_pos_cp))\n",
    "print(\"false pos:\", len(false_pos_cp))\n",
    "print(\"false neg:\", len(false_neg_cp))\n",
    "display(true_pos_cp.head(1))\n",
    "display(false_pos_cp.head(1))\n",
    "print(\"all true:\", len(all_true_cp))\n",
    "print(\"all\", len(cip_pipeline_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c038ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true pos: 291\n",
      "false pos: 310\n",
      "false neg: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cve_id</th>\n",
       "      <th>cve_published</th>\n",
       "      <th>cve_descriptions</th>\n",
       "      <th>cve_metrics</th>\n",
       "      <th>cve_references</th>\n",
       "      <th>cve_configurations</th>\n",
       "      <th>cve_primary_cwe</th>\n",
       "      <th>cve_tags</th>\n",
       "      <th>issue_owner_repo</th>\n",
       "      <th>issue_body</th>\n",
       "      <th>...</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>label</th>\n",
       "      <th>issue_msg</th>\n",
       "      <th>issue_msg_n_tokens</th>\n",
       "      <th>issue_embedding</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>gpt_description</th>\n",
       "      <th>gpt_vulnerability</th>\n",
       "      <th>gpt_confidence</th>\n",
       "      <th>gpt_is_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVE-2021-39528</td>\n",
       "      <td>2021-09-20T16:15:12.077</td>\n",
       "      <td>An issue was discovered in libredwg through v0...</td>\n",
       "      <td>{'cvssMetricV2': [{'acInsufInfo': False, 'base...</td>\n",
       "      <td>[{'source': 'cve@mitre.org', 'tags': ['Exploit...</td>\n",
       "      <td>[{'nodes': [{'cpeMatch': array([{'criteria': '...</td>\n",
       "      <td>415</td>\n",
       "      <td>[Exploit, Issue Tracking, Patch, Third Party A...</td>\n",
       "      <td>[LibreDWG, libredwg]</td>\n",
       "      <td>## System info\\r\\n\\r\\nUbuntu X64, gcc (Ubuntu ...</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>This is a GitHub Issue\\nrepo:libredwg\\nowner:L...</td>\n",
       "      <td>2400</td>\n",
       "      <td>[-0.03039676696062088, 0.01844700239598751, -0...</td>\n",
       "      <td>308</td>\n",
       "      <td>The issue describes a double free vulnerabilit...</td>\n",
       "      <td># Double Free Vulnerability\\n\\n## Description\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cve_id            cve_published  \\\n",
       "4  CVE-2021-39528  2021-09-20T16:15:12.077   \n",
       "\n",
       "                                    cve_descriptions  \\\n",
       "4  An issue was discovered in libredwg through v0...   \n",
       "\n",
       "                                         cve_metrics  \\\n",
       "4  {'cvssMetricV2': [{'acInsufInfo': False, 'base...   \n",
       "\n",
       "                                      cve_references  \\\n",
       "4  [{'source': 'cve@mitre.org', 'tags': ['Exploit...   \n",
       "\n",
       "                                  cve_configurations cve_primary_cwe  \\\n",
       "4  [{'nodes': [{'cpeMatch': array([{'criteria': '...             415   \n",
       "\n",
       "                                            cve_tags      issue_owner_repo  \\\n",
       "4  [Exploit, Issue Tracking, Patch, Third Party A...  [LibreDWG, libredwg]   \n",
       "\n",
       "                                          issue_body  ... issue_number label  \\\n",
       "4  ## System info\\r\\n\\r\\nUbuntu X64, gcc (Ubuntu ...  ...          256  True   \n",
       "\n",
       "                                           issue_msg issue_msg_n_tokens  \\\n",
       "4  This is a GitHub Issue\\nrepo:libredwg\\nowner:L...               2400   \n",
       "\n",
       "                                     issue_embedding __index_level_0__  \\\n",
       "4  [-0.03039676696062088, 0.01844700239598751, -0...               308   \n",
       "\n",
       "                                     gpt_description  \\\n",
       "4  The issue describes a double free vulnerabilit...   \n",
       "\n",
       "                                   gpt_vulnerability  gpt_confidence  \\\n",
       "4  # Double Free Vulnerability\\n\\n## Description\\...               5   \n",
       "\n",
       "  gpt_is_relevant  \n",
       "4            True  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cve_id</th>\n",
       "      <th>cve_published</th>\n",
       "      <th>cve_descriptions</th>\n",
       "      <th>cve_metrics</th>\n",
       "      <th>cve_references</th>\n",
       "      <th>cve_configurations</th>\n",
       "      <th>cve_primary_cwe</th>\n",
       "      <th>cve_tags</th>\n",
       "      <th>issue_owner_repo</th>\n",
       "      <th>issue_body</th>\n",
       "      <th>...</th>\n",
       "      <th>issue_number</th>\n",
       "      <th>label</th>\n",
       "      <th>issue_msg</th>\n",
       "      <th>issue_msg_n_tokens</th>\n",
       "      <th>issue_embedding</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>gpt_description</th>\n",
       "      <th>gpt_vulnerability</th>\n",
       "      <th>gpt_confidence</th>\n",
       "      <th>gpt_is_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No_CWE</td>\n",
       "      <td>None</td>\n",
       "      <td>[cesanta, mjs]</td>\n",
       "      <td># s2o\\r\\n## Environment\\r\\nUbuntu 22.04.3 LTS\\...</td>\n",
       "      <td>...</td>\n",
       "      <td>281</td>\n",
       "      <td>False</td>\n",
       "      <td>This is a GitHub Issue\\nrepo:mjs\\nowner:cesant...</td>\n",
       "      <td>1673</td>\n",
       "      <td>[-0.01231892965734005, -0.0185470562428236, 0....</td>\n",
       "      <td>3444</td>\n",
       "      <td>The issue describes a segmentation fault (SEGV...</td>\n",
       "      <td># Out-of-Bounds Read\\n\\n## Description\\nThe pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cve_id cve_published cve_descriptions cve_metrics cve_references  \\\n",
       "1   None          None             None        None           None   \n",
       "\n",
       "  cve_configurations cve_primary_cwe cve_tags issue_owner_repo  \\\n",
       "1               None          No_CWE     None   [cesanta, mjs]   \n",
       "\n",
       "                                          issue_body  ... issue_number  label  \\\n",
       "1  # s2o\\r\\n## Environment\\r\\nUbuntu 22.04.3 LTS\\...  ...          281  False   \n",
       "\n",
       "                                           issue_msg issue_msg_n_tokens  \\\n",
       "1  This is a GitHub Issue\\nrepo:mjs\\nowner:cesant...               1673   \n",
       "\n",
       "                                     issue_embedding __index_level_0__  \\\n",
       "1  [-0.01231892965734005, -0.0185470562428236, 0....              3444   \n",
       "\n",
       "                                     gpt_description  \\\n",
       "1  The issue describes a segmentation fault (SEGV...   \n",
       "\n",
       "                                   gpt_vulnerability  gpt_confidence  \\\n",
       "1  # Out-of-Bounds Read\\n\\n## Description\\nThe pr...               5   \n",
       "\n",
       "  gpt_is_relevant  \n",
       "1            True  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all true: 601\n",
      "all 1763\n"
     ]
    }
   ],
   "source": [
    "true_pos_few = test_few_df[test_few_df.gpt_is_relevant & ~test_few_df.cve_id.isna()]\n",
    "false_pos_few = test_few_df[test_few_df.gpt_is_relevant & test_few_df.cve_id.isna()]\n",
    "false_neg_few = test_few_df[~test_few_df.gpt_is_relevant & ~test_few_df.cve_id.isna()]\n",
    "all_true_few = test_few_df[test_few_df.gpt_is_relevant]\n",
    "\n",
    "print(\"true pos:\", len(true_pos_few))\n",
    "print(\"false pos:\", len(false_pos_few))\n",
    "print(\"false neg:\", len(false_neg_few))\n",
    "display(true_pos_few.head(1))\n",
    "display(false_pos_few.head(1))\n",
    "print(\"all true:\", len(all_true_few))\n",
    "print(\"all\", len(test_few_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_zero = load_dataset(\n",
    "    \"Eathus/github-issues-vul-detection-gpt-zero-vul-desc-results\", split=\"test\"\n",
    ")\n",
    "test_zero_df = test_zero.to_pandas()\n",
    "test_zero_df = test_zero_df[\n",
    "    ~test_zero_df.duplicated(subset=\"issue_github_id\", keep=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38289421",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_zero = test_zero_df[test_zero_df.gpt_is_relevant & ~test_zero_df.cve_id.isna()]\n",
    "false_pos_zero = test_zero_df[test_zero_df.gpt_is_relevant & test_zero_df.cve_id.isna()]\n",
    "all_true_zero = test_zero_df[test_zero_df.gpt_is_relevant]\n",
    "\n",
    "print(len(true_pos_zero))\n",
    "display(true_pos_zero.head(1))\n",
    "print(len(false_pos_zero))\n",
    "display(false_pos_zero.head(1))\n",
    "print(\"all true:\", len(all_true_zero))\n",
    "print(\"all\", len(test_zero_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_few.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)  # No truncation of column content\n",
    "pd.set_option(\"display.max_rows\", None)  # Show all rows\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b18b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_few[~true_pos_few.gpt_vulnerability.str.contains(\"Demonstrative Scenario\")][\n",
    "    \"gpt_vulnerability\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae2891a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bare_rag_label(\n",
    "    data_df, vectorstore, match_col=\"gpt_vulnerability\", k=1\n",
    "):  # max for k is 20\n",
    "    ret_df = data_df.copy()\n",
    "    faiss_retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={\n",
    "            \"k\": k,\n",
    "        }\n",
    "    )\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[faiss_retriever],\n",
    "        weights=[1],\n",
    "        # retrievers=[faiss_retriever], weights=[1]\n",
    "    )\n",
    "\n",
    "    # display(ret_df[ret_df['cve_primary_cwe'].isna()])\n",
    "    def label(desc):\n",
    "        try:\n",
    "            ret = list(\n",
    "                set([x.metadata[\"CWE_ID\"] for x in ensemble_retriever.invoke(desc)])\n",
    "            )\n",
    "            # print(len(ret))\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"General error processing message: {e}\")\n",
    "            return\n",
    "\n",
    "    ret_df[\"rag_candidates\"] = ret_df[match_col].progress_map(label)\n",
    "    ret_df[\"rag_label\"] = ret_df.apply(\n",
    "        lambda row: (\n",
    "            row[\"cve_primary_cwe\"]\n",
    "            if row[\"cve_primary_cwe\"] in row[\"rag_candidates\"]\n",
    "            else row[\"rag_candidates\"][0]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fc11ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 291/291 [00:11<00:00, 24.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cve_id</th>\n",
       "      <th>cve_published</th>\n",
       "      <th>cve_descriptions</th>\n",
       "      <th>cve_metrics</th>\n",
       "      <th>cve_references</th>\n",
       "      <th>cve_configurations</th>\n",
       "      <th>cve_primary_cwe</th>\n",
       "      <th>cve_tags</th>\n",
       "      <th>issue_owner_repo</th>\n",
       "      <th>issue_body</th>\n",
       "      <th>...</th>\n",
       "      <th>issue_msg</th>\n",
       "      <th>issue_msg_n_tokens</th>\n",
       "      <th>issue_embedding</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>gpt_description</th>\n",
       "      <th>gpt_vulnerability</th>\n",
       "      <th>gpt_confidence</th>\n",
       "      <th>gpt_is_relevant</th>\n",
       "      <th>rag_candidates</th>\n",
       "      <th>rag_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CVE-2020-19667</td>\n",
       "      <td>2020-11-20T16:15:15.557</td>\n",
       "      <td>Stack-based buffer overflow and unconditional ...</td>\n",
       "      <td>{'cvssMetricV2': [{'acInsufInfo': False, 'base...</td>\n",
       "      <td>[{'source': 'cve@mitre.org', 'tags': ['Exploit...</td>\n",
       "      <td>[{'nodes': [{'cpeMatch': array([{'criteria': '...</td>\n",
       "      <td>787</td>\n",
       "      <td>[Exploit, Issue Tracking, Third Party Advisory]</td>\n",
       "      <td>[ImageMagick, ImageMagick]</td>\n",
       "      <td>### Prerequisites\\r\\n\\r\\n- [✅ ] I have written...</td>\n",
       "      <td>...</td>\n",
       "      <td>This is a GitHub Issue\\nrepo:ImageMagick\\nowne...</td>\n",
       "      <td>5289</td>\n",
       "      <td>[-0.03310983255505562, 0.013431346975266933, -...</td>\n",
       "      <td>171</td>\n",
       "      <td>The issue describes a stack buffer overflow vu...</td>\n",
       "      <td># Stack Buffer Overflow\\n\\n## Description\\nA s...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[787, 120, 123, 131, 119, 806, 122, 680, 805, ...</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CVE-2023-29374</td>\n",
       "      <td>2023-04-05T02:15:37.340</td>\n",
       "      <td>In LangChain through 0.0.131, the LLMMathChain...</td>\n",
       "      <td>{'cvssMetricV2': None, 'cvssMetricV30': None, ...</td>\n",
       "      <td>[{'source': 'cve@mitre.org', 'tags': ['Issue T...</td>\n",
       "      <td>[{'nodes': [{'cpeMatch': array([{'criteria': '...</td>\n",
       "      <td>74</td>\n",
       "      <td>[Exploit, Issue Tracking, Patch]</td>\n",
       "      <td>[hwchase17, langchain]</td>\n",
       "      <td>#Overview\\r\\n\\r\\nllm math and PAL both use `ex...</td>\n",
       "      <td>...</td>\n",
       "      <td>This is a GitHub Issue\\nrepo:langchain\\nowner:...</td>\n",
       "      <td>1765</td>\n",
       "      <td>[-0.02437249757349491, -0.007051460444927216, ...</td>\n",
       "      <td>640</td>\n",
       "      <td>The issue highlights a potential security vuln...</td>\n",
       "      <td># Code Injection Vulnerability\\n\\n## Descripti...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[141, 627, 94, 150, 95, 1120, 146, 75, 149, 96...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>CVE-2023-34151</td>\n",
       "      <td>2023-05-30T22:15:11.000</td>\n",
       "      <td>A vulnerability was found in ImageMagick. This...</td>\n",
       "      <td>{'cvssMetricV2': None, 'cvssMetricV30': None, ...</td>\n",
       "      <td>[{'source': 'secalert@redhat.com', 'tags': ['T...</td>\n",
       "      <td>[{'nodes': [{'cpeMatch': array([{'criteria': '...</td>\n",
       "      <td>190</td>\n",
       "      <td>[Exploit, Issue Tracking, Patch]</td>\n",
       "      <td>[ImageMagick, ImageMagick]</td>\n",
       "      <td>### ImageMagick version\\r\\n\\r\\n7.1.30-0\\r\\n\\r\\...</td>\n",
       "      <td>...</td>\n",
       "      <td>This is a GitHub Issue\\nrepo:ImageMagick\\nowne...</td>\n",
       "      <td>2161</td>\n",
       "      <td>[-0.013025580905377865, 0.009491877630352974, ...</td>\n",
       "      <td>715</td>\n",
       "      <td>The issue describes a vulnerability related to...</td>\n",
       "      <td># Type Conversion Error Leading to Undefined B...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>[241, 196, 192, 1287, 681, 1024, 195, 197, 475...</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cve_id            cve_published  \\\n",
       "79   CVE-2020-19667  2020-11-20T16:15:15.557   \n",
       "49   CVE-2023-29374  2023-04-05T02:15:37.340   \n",
       "509  CVE-2023-34151  2023-05-30T22:15:11.000   \n",
       "\n",
       "                                      cve_descriptions  \\\n",
       "79   Stack-based buffer overflow and unconditional ...   \n",
       "49   In LangChain through 0.0.131, the LLMMathChain...   \n",
       "509  A vulnerability was found in ImageMagick. This...   \n",
       "\n",
       "                                           cve_metrics  \\\n",
       "79   {'cvssMetricV2': [{'acInsufInfo': False, 'base...   \n",
       "49   {'cvssMetricV2': None, 'cvssMetricV30': None, ...   \n",
       "509  {'cvssMetricV2': None, 'cvssMetricV30': None, ...   \n",
       "\n",
       "                                        cve_references  \\\n",
       "79   [{'source': 'cve@mitre.org', 'tags': ['Exploit...   \n",
       "49   [{'source': 'cve@mitre.org', 'tags': ['Issue T...   \n",
       "509  [{'source': 'secalert@redhat.com', 'tags': ['T...   \n",
       "\n",
       "                                    cve_configurations cve_primary_cwe  \\\n",
       "79   [{'nodes': [{'cpeMatch': array([{'criteria': '...             787   \n",
       "49   [{'nodes': [{'cpeMatch': array([{'criteria': '...              74   \n",
       "509  [{'nodes': [{'cpeMatch': array([{'criteria': '...             190   \n",
       "\n",
       "                                            cve_tags  \\\n",
       "79   [Exploit, Issue Tracking, Third Party Advisory]   \n",
       "49                  [Exploit, Issue Tracking, Patch]   \n",
       "509                 [Exploit, Issue Tracking, Patch]   \n",
       "\n",
       "               issue_owner_repo  \\\n",
       "79   [ImageMagick, ImageMagick]   \n",
       "49       [hwchase17, langchain]   \n",
       "509  [ImageMagick, ImageMagick]   \n",
       "\n",
       "                                            issue_body  ...  \\\n",
       "79   ### Prerequisites\\r\\n\\r\\n- [✅ ] I have written...  ...   \n",
       "49   #Overview\\r\\n\\r\\nllm math and PAL both use `ex...  ...   \n",
       "509  ### ImageMagick version\\r\\n\\r\\n7.1.30-0\\r\\n\\r\\...  ...   \n",
       "\n",
       "                                             issue_msg issue_msg_n_tokens  \\\n",
       "79   This is a GitHub Issue\\nrepo:ImageMagick\\nowne...               5289   \n",
       "49   This is a GitHub Issue\\nrepo:langchain\\nowner:...               1765   \n",
       "509  This is a GitHub Issue\\nrepo:ImageMagick\\nowne...               2161   \n",
       "\n",
       "                                       issue_embedding __index_level_0__  \\\n",
       "79   [-0.03310983255505562, 0.013431346975266933, -...               171   \n",
       "49   [-0.02437249757349491, -0.007051460444927216, ...               640   \n",
       "509  [-0.013025580905377865, 0.009491877630352974, ...               715   \n",
       "\n",
       "                                       gpt_description  \\\n",
       "79   The issue describes a stack buffer overflow vu...   \n",
       "49   The issue highlights a potential security vuln...   \n",
       "509  The issue describes a vulnerability related to...   \n",
       "\n",
       "                                     gpt_vulnerability  gpt_confidence  \\\n",
       "79   # Stack Buffer Overflow\\n\\n## Description\\nA s...               5   \n",
       "49   # Code Injection Vulnerability\\n\\n## Descripti...               5   \n",
       "509  # Type Conversion Error Leading to Undefined B...               5   \n",
       "\n",
       "     gpt_is_relevant                                     rag_candidates  \\\n",
       "79              True  [787, 120, 123, 131, 119, 806, 122, 680, 805, ...   \n",
       "49              True  [141, 627, 94, 150, 95, 1120, 146, 75, 149, 96...   \n",
       "509             True  [241, 196, 192, 1287, 681, 1024, 195, 197, 475...   \n",
       "\n",
       "    rag_label  \n",
       "79        787  \n",
       "49        141  \n",
       "509       190  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Must be before pandarallel init\n",
    "rag_labeled_df = bare_rag_label(\n",
    "    true_pos_few, vectorstore_gpt, match_col=\"gpt_vulnerability\", k=13\n",
    ")\n",
    "display(rag_labeled_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# test\n",
    "ds = Dataset.from_pandas(rag_labeled_df.drop(columns='__index_level_0__'))\n",
    "ds.push_to_hub(\"Eathus/github-issues-vul-label-rag-results\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "027e7b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.962199312714777\n",
      "13\n",
      "13\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "cl_lengths = [len(cands) for cands in rag_labeled_df.rag_candidates.to_list()]\n",
    "print(stat.mean(cl_lengths))\n",
    "print(stat.median(cl_lengths))\n",
    "print(max(cl_lengths))\n",
    "print(min(cl_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e36a4673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8006872852233677\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1050       1.00      1.00      1.00         1\n",
      "         106       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         1\n",
      "         119       1.00      0.57      0.73         7\n",
      "         120       1.00      0.86      0.92        14\n",
      "         122       1.00      1.00      1.00         1\n",
      "         125       1.00      0.18      0.30        17\n",
      "        1251       0.00      0.00      0.00         0\n",
      "        1295       0.00      0.00      0.00         0\n",
      "        1325       0.00      0.00      0.00         0\n",
      "        1333       1.00      1.00      1.00         1\n",
      "         141       0.00      0.00      0.00         0\n",
      "        1422       0.00      0.00      0.00         0\n",
      "         150       1.00      1.00      1.00         1\n",
      "         167       0.00      0.00      0.00         0\n",
      "         190       1.00      1.00      1.00         4\n",
      "         194       0.00      0.00      0.00         0\n",
      "          20       1.00      0.67      0.80         3\n",
      "         200       0.00      0.00      0.00         1\n",
      "         212       1.00      1.00      1.00         1\n",
      "          22       0.00      0.00      0.00         1\n",
      "         238       0.00      0.00      0.00         0\n",
      "         241       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         0\n",
      "         280       1.00      1.00      1.00         1\n",
      "         283       0.00      0.00      0.00         1\n",
      "         285       0.00      0.00      0.00         0\n",
      "         295       1.00      1.00      1.00         1\n",
      "         306       1.00      1.00      1.00         1\n",
      "         369       1.00      1.00      1.00         1\n",
      "          37       0.00      0.00      0.00         0\n",
      "         372       1.00      1.00      1.00         1\n",
      "         400       0.00      0.00      0.00         2\n",
      "         401       1.00      0.94      0.97        18\n",
      "         407       1.00      1.00      1.00         1\n",
      "         415       0.30      1.00      0.46         3\n",
      "         416       1.00      0.90      0.95        10\n",
      "         434       1.00      0.50      0.67         2\n",
      "         476       0.95      0.98      0.96        56\n",
      "         532       1.00      1.00      1.00         3\n",
      "         562       0.00      0.00      0.00         0\n",
      "         601       1.00      1.00      1.00         1\n",
      "         606       0.00      0.00      0.00         0\n",
      "         617       1.00      1.00      1.00        15\n",
      "         627       0.00      0.00      0.00         0\n",
      "         650       0.00      0.00      0.00         0\n",
      "         665       0.00      0.00      0.00         1\n",
      "         703       0.00      0.00      0.00         0\n",
      "         704       0.00      0.00      0.00         1\n",
      "         732       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         2\n",
      "         754       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         1\n",
      "         770       1.00      0.57      0.73        14\n",
      "          78       1.00      1.00      1.00         2\n",
      "         787       0.77      0.82      0.79        56\n",
      "          79       1.00      1.00      1.00         8\n",
      "         798       1.00      1.00      1.00         2\n",
      "         862       0.00      0.00      0.00         1\n",
      "          89       1.00      0.81      0.89        26\n",
      "         918       1.00      1.00      1.00         1\n",
      "          94       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.80       291\n",
      "   macro avg       0.53      0.50      0.50       291\n",
      "weighted avg       0.89      0.80      0.82       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_rag(rag_labeled_df, \"rag_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0bb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_gpt_fusion = create_vectorstore(documents, \"tmp/faiss_gpt_fusion_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55300f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(\n",
    "    vectorstore, bm25, docs, query: str, k: int = 5, alpha: float = 0.5\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Perform fusion retrieval combining keyword-based (BM25) and vector-based search.\n",
    "\n",
    "    Args:\n",
    "    vectorstore (VectorStore): The vectorstore containing the documents.\n",
    "    bm25 (BM25Okapi): Pre-computed BM25 index.\n",
    "    query (str): The query string.\n",
    "    k (int): The number of documents to retrieve.\n",
    "    alpha (float): The weight for vector search scores (1-alpha will be the weight for BM25 scores).\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: The top k documents based on the combined scores.\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    # Step 2: BM25 scores\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (\n",
    "        np.max(bm25_scores) - np.min(bm25_scores) + epsilon\n",
    "    )\n",
    "\n",
    "    # Build CWE_ID to BM25 score map\n",
    "    bm25_score_dict = {\n",
    "        doc.metadata[\"CWE_ID\"]: score for doc, score in zip(docs, bm25_scores)\n",
    "    }\n",
    "\n",
    "    # Step 3: Vector search\n",
    "    vector_results = vectorstore.similarity_search_with_score(\n",
    "        query, k=vectorstore.index.ntotal\n",
    "    )\n",
    "    docs_vec, vec_scores_raw = zip(*vector_results)\n",
    "\n",
    "    # Normalize vector scores\n",
    "    vec_scores = 1 - (np.array(vec_scores_raw) - np.min(vec_scores_raw)) / (\n",
    "        np.max(vec_scores_raw) - np.min(vec_scores_raw) + epsilon\n",
    "    )\n",
    "\n",
    "    # Combine scores safely\n",
    "    def combine(vec, bm25):\n",
    "        return alpha * vec + (1 - alpha) * bm25\n",
    "\n",
    "    # Combine scores for docs with matching CWE_IDs\n",
    "    score_dict = {}\n",
    "    for doc_vec, vec_score in zip(docs_vec, vec_scores):\n",
    "        cwe_id = doc_vec.metadata[\"CWE_ID\"]\n",
    "        if cwe_id in bm25_score_dict:\n",
    "            bm25_score = bm25_score_dict[cwe_id]\n",
    "            combined_score = combine(vec_score, bm25_score)\n",
    "            score_dict[cwe_id] = (doc_vec, combined_score)\n",
    "\n",
    "    # Sort and return top k documents\n",
    "    sorted_doc_scores = sorted(score_dict.values(), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in sorted_doc_scores[:k]]\n",
    "\n",
    "\n",
    "def fusion_rag_label(\n",
    "    data_df, vectorstore, bm25_docs, match_col=\"gpt_vulnerability\", k=1, alpha=0.5\n",
    "):  # max for k is 20\n",
    "    ret_df = data_df.copy()\n",
    "\n",
    "    tokenized_docs = [doc.page_content.split() for doc in bm25_docs]\n",
    "    bm25_retriever = BM25Okapi(tokenized_docs)\n",
    "\n",
    "    # display(ret_df[ret_df['cve_primary_cwe'].isna()])\n",
    "    def label(desc):\n",
    "        try:\n",
    "            ret = list(\n",
    "                set(\n",
    "                    [\n",
    "                        x.metadata[\"CWE_ID\"]\n",
    "                        for x in fusion_retrieval(\n",
    "                            vectorstore, bm25_retriever, bm25_docs, desc, k, alpha\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            # print(len(ret))\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"General error processing message: {e}\")\n",
    "            return\n",
    "\n",
    "    ret_df[\"rag_candidates\"] = ret_df[match_col].progress_map(label)\n",
    "    ret_df[\"rag_label\"] = ret_df.apply(\n",
    "        lambda row: (\n",
    "            row[\"cve_primary_cwe\"]\n",
    "            if row[\"cve_primary_cwe\"] in row[\"rag_candidates\"]\n",
    "            else row[\"rag_candidates\"][0]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32466353",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_rag_labeled_df = fusion_rag_label(\n",
    "    true_pos_few,\n",
    "    vectorstore_gpt_fusion,\n",
    "    bm25_docs1,\n",
    "    match_col=\"gpt_vulnerability\",\n",
    "    k=50,\n",
    "    alpha=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "cl_lengths = [len(cands) for cands in fusion_rag_labeled_df.rag_candidates.to_list()]\n",
    "print(stat.mean(cl_lengths))\n",
    "print(stat.median(cl_lengths))\n",
    "print(max(cl_lengths))\n",
    "print(min(cl_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rag(fusion_rag_labeled_df, \"rag_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31001e5",
   "metadata": {},
   "source": [
    "## RAPTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from rag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwes = load_dataset(\"Eathus/cwe_view1000_list_gpt_few_cwe_desc\", split=\"train\")\n",
    "cwes_df = cwes.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from rag import *\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"tmp/view_CWE-1000_all_weaknesses.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "old_documents = [\n",
    "    create_ordered_cwe_document(weakness, old=True) for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "document_dict = {doc.metadata[\"CWE_ID\"]: doc for doc in old_documents}\n",
    "cwes_df[\"RAG_Doc\"] = cwes_df.apply(\n",
    "    lambda x: Document(\n",
    "        page_content=x.gpt_cwe_description,\n",
    "        metadata={\n",
    "            **document_dict[x.ID].metadata,  # Original metadata\n",
    "            \"Child_IDs\": x.Children.tolist(),  # New field\n",
    "        },\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            cwe.Summary if cwe.Abstraction == \"Pillar\" else cwe.gpt_cwe_description\n",
    "        ),\n",
    "        metadata={\n",
    "            \"CWE_ID\": cwe.ID,  # Original metadata\n",
    "            \"Abstraction\": CWE_abstraction[cwe.Abstraction.upper()].value,  # New field\n",
    "            \"Child_IDs\": cwe.Children.tolist(),  # New field\n",
    "        },\n",
    "    )\n",
    "    for _, cwe in cwes_df.iterrows()\n",
    "]\n",
    "old_documents = [\n",
    "    Document(\n",
    "        page_content=cwe.Summary,\n",
    "        metadata={\n",
    "            \"CWE_ID\": cwe.ID,  # Original metadata\n",
    "            \"Abstraction\": CWE_abstraction[cwe.Abstraction.upper()].value,  # New field\n",
    "            \"Child_IDs\": cwe.Children.tolist(),  # New field\n",
    "        },\n",
    "    )\n",
    "    for _, cwe in cwes_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_norm_documents = [\n",
    "    create_ordered_cwe_document(weakness, CWE_doc_density.NORM, old=True)\n",
    "    for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "old_heavy_documents = [\n",
    "    create_ordered_cwe_document(weakness, CWE_doc_density.HEAVY, old=True)\n",
    "    for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "old_medium_documents = [\n",
    "    create_ordered_cwe_document(weakness, CWE_doc_density.MEDIUM, old=True)\n",
    "    for weakness in data[\"Weaknesses\"]\n",
    "]\n",
    "\n",
    "old_norm_documents = [\n",
    "    Document(\n",
    "        page_content=doc.page_content,\n",
    "        metadata={\n",
    "            \"CWE_ID\": doc.metadata[\"CWE_ID\"],  # Original metadata\n",
    "            \"Abstraction\": doc.metadata[\"Abstraction\"],\n",
    "            \"Child_IDs\": cwes_df.loc[cwes_df.ID == doc.metadata[\"CWE_ID\"], \"Children\"]\n",
    "            .iloc[0]\n",
    "            .tolist(),  # New field\n",
    "        },\n",
    "    )\n",
    "    for doc in old_norm_documents\n",
    "]\n",
    "old_norm_documents = add_sequential_ids(old_norm_documents)\n",
    "\n",
    "old_heavy_documents = [\n",
    "    Document(\n",
    "        page_content=doc.page_content,\n",
    "        metadata={\n",
    "            \"CWE_ID\": doc.metadata[\"CWE_ID\"],  # Original metadata\n",
    "            \"Abstraction\": doc.metadata[\"Abstraction\"],\n",
    "            \"Child_IDs\": cwes_df.loc[cwes_df.ID == doc.metadata[\"CWE_ID\"], \"Children\"]\n",
    "            .iloc[0]\n",
    "            .tolist(),  # New field\n",
    "        },\n",
    "    )\n",
    "    for doc in old_heavy_documents\n",
    "]\n",
    "old_heavy_documents = add_sequential_ids(old_heavy_documents)\n",
    "\n",
    "old_medium_documents = [\n",
    "    Document(\n",
    "        page_content=doc.page_content,\n",
    "        metadata={\n",
    "            \"CWE_ID\": doc.metadata[\"CWE_ID\"],  # Original metadata\n",
    "            \"Abstraction\": doc.metadata[\"Abstraction\"],\n",
    "            \"Child_IDs\": cwes_df.loc[cwes_df.ID == doc.metadata[\"CWE_ID\"], \"Children\"]\n",
    "            .iloc[0]\n",
    "            .tolist(),  # New field\n",
    "        },\n",
    "    )\n",
    "    for doc in old_medium_documents\n",
    "]\n",
    "old_medium_documents = add_sequential_ids(old_medium_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_docs(docs, echo=False):\n",
    "    all_docs = []\n",
    "    for doc in docs:\n",
    "        all_docs.extend(split_cwe_document(doc))\n",
    "    all_docs = add_sequential_ids(all_docs)\n",
    "    if echo:\n",
    "        print(f\"Original: {len(documents)} docs\")\n",
    "        print(f\"After splitting: {len(all_docs)} docs\")\n",
    "        print(f\"Max tokens: {max(count_tokens(d.page_content) for d in all_docs)}\")\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = split_docs(documents, True)\n",
    "old_docs = split_docs(old_documents, True)\n",
    "bm25_docs0 = [\n",
    "    Document(\n",
    "        page_content=cwe.page_content,\n",
    "        metadata=cwe.metadata,\n",
    "    )\n",
    "    for cwe in old_documents\n",
    "]\n",
    "bm25_docs1 = [\n",
    "    Document(\n",
    "        page_content=remove_subtitle(cwe.page_content, [\"Extended Description\"]),\n",
    "        metadata=cwe.metadata,\n",
    "    )\n",
    "    for cwe in old_documents\n",
    "]\n",
    "all_docs_bm25_0 = split_docs(bm25_docs0, True)\n",
    "all_docs_bm25_1 = split_docs(bm25_docs1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02604146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_few = load_dataset(\n",
    "    \"Eathus/github-issues-vul-detection-gpt-few-strict-vul-desc-results\", split=\"test\"\n",
    ")\n",
    "test_few_df = test_few.to_pandas()\n",
    "test_few_df = test_few_df[~test_few_df.duplicated(subset=\"issue_github_id\", keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_few = test_few_df[test_few_df.gpt_is_relevant & ~test_few_df.cve_id.isna()]\n",
    "false_pos_few = test_few_df[test_few_df.gpt_is_relevant & test_few_df.cve_id.isna()]\n",
    "all_true_few = test_few_df[test_few_df.gpt_is_relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = add_sequential_ids(documents)\n",
    "raptor_vectorstore_gpt = create_vectorstore(\n",
    "    all_docs, \"tmp/chromadb_indices_gpt\", \"gpt_index\", Vectorstore.CHROMADB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05762e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_vectorstore_old = create_vectorstore(\n",
    "    old_docs, \"tmp/chromadb_indices_old\", \"old_index\", Vectorstore.CHROMADB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed54b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_vectorstore_gpt_condensed = create_vectorstore(\n",
    "    documents, \"tmp/chromadb_indices_gpt_condensed\", \"gpt_index\", Vectorstore.CHROMADB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20caeb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_vectorstore_norm = create_vectorstore(\n",
    "    old_norm_documents, \"tmp/chromadb_indices_norm\", \"norm_index\", Vectorstore.CHROMADB\n",
    ")\n",
    "raptor_vectorstore_medium = create_vectorstore(\n",
    "    old_medium_documents,\n",
    "    \"tmp/chromadb_indices_medium\",\n",
    "    \"medium_index\",\n",
    "    Vectorstore.CHROMADB,\n",
    ")\n",
    "raptor_vectorstore_heavy = create_vectorstore(\n",
    "    old_heavy_documents,\n",
    "    \"tmp/chromadb_indices_heavy\",\n",
    "    \"heavy_index\",\n",
    "    Vectorstore.CHROMADB,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_rag_labeled_df = raptor_rag_label(\n",
    "    true_pos_few,\n",
    "    raptor_vectorstore_medium,\n",
    "    match_col=\"gpt_vulnerability\",\n",
    "    # device=\"cpu\",\n",
    "    bm25_docs=old_medium_documents,\n",
    "    k_list=[3, 12, 4, 1, 1],\n",
    "    top_abstraction=CWE_abstraction.PILLAR,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "display(raptor_rag_labeled_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb7e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_rag_labeled_df = raptor_rag_label_optimized(\n",
    "    true_pos_few,\n",
    "    raptor_vectorstore_gpt,\n",
    "    match_col=\"gpt_vulnerability\",\n",
    "    k_list=[4, 7, 4, 2, 1],\n",
    "    device=\"cpu\",\n",
    "    max_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ffbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "cl_lengths = [len(cands) for cands in raptor_rag_labeled_df.rag_candidates.to_list()]\n",
    "print(stat.mean(cl_lengths))\n",
    "print(stat.median(cl_lengths))\n",
    "print(max(cl_lengths))\n",
    "print(min(cl_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rag(raptor_rag_labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "OPENAI_API_KEY_KTH = os.getenv(\"OPENAI_API_KEY_KTH\")\n",
    "\n",
    "llm = OpenAI(temperature=0, api_key=OPENAI_API_KEY_KTH)\n",
    "\n",
    "\n",
    "def hierarchical_retrieval(\n",
    "    query: str,\n",
    "    vectorstore,\n",
    "    hierarchy_cache,\n",
    "    k_list: List = [3, 10, 5, 2, 1],\n",
    "    top_abstraction=CWE_abstraction.PILLAR,\n",
    ") -> List[Document]:\n",
    "\n",
    "    k_dict = {\n",
    "        \"PILLAR\": k_list[0],\n",
    "        \"CLASS\": k_list[1],\n",
    "        \"BASE\": k_list[2],\n",
    "        \"VARIANT\": k_list[3],\n",
    "        \"COMPOUND\": k_list[4],\n",
    "    }\n",
    "\n",
    "    all_retrieved_docs = []\n",
    "    child_ids = None  # Initialize child_ids\n",
    "    level = top_abstraction\n",
    "    compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        # Define metadata filter\n",
    "        CWE_abstraction(i)\n",
    "        if child_ids:\n",
    "            filter_condition = {\"CWE_ID\": {\"$in\": child_ids}}\n",
    "        else:\n",
    "            filter_condition = {\"Abstraction\": {\"$eq\": level.value}}\n",
    "\n",
    "        base_retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": k_dict[level.name], \"filter\": filter_condition}\n",
    "        )\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=base_retriever\n",
    "        )\n",
    "\n",
    "        # Retrieve documents with the defined filter\n",
    "        level_docs = compression_retriever.invoke(query)\n",
    "        all_retrieved_docs.extend(level_docs)\n",
    "\n",
    "        # Prepare child_ids for the next iteration\n",
    "        if level_docs:\n",
    "            max_level = max([doc.metadata.get(\"Abstraction\", 0) for doc in level_docs])\n",
    "            level = CWE_abstraction(max_level)\n",
    "            child_ids = []\n",
    "            for doc in level_docs:\n",
    "                child_ids.extend(\n",
    "                    hierarchy_cache.get(doc.metadata[\"CWE_ID\"], {}).get(\"children\", [])\n",
    "                )\n",
    "            child_ids = list(set(child_ids))\n",
    "        else:\n",
    "            child_ids = None  # Reset if no documents found or at the lowest level\n",
    "\n",
    "        if not child_ids or i > 4:\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "    return list({doc.metadata[\"id\"]: doc for doc in all_retrieved_docs}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a928e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raptor_hierarchy_rag_label(\n",
    "    data_df,\n",
    "    vectorstore,\n",
    "    match_col=\"gpt_vulnerability\",\n",
    "    k_list: List = [3, 10, 5, 2, 0],\n",
    "    # max_workers=10,\n",
    "    top_abstraction=CWE_abstraction.PILLAR,\n",
    "    max_workers=15,\n",
    "):  # max for k is 20\n",
    "    ret_df = data_df.copy()\n",
    "\n",
    "    hierarchy_cache = {}\n",
    "    all_metadata = vectorstore.get()[\"metadatas\"]\n",
    "    for meta in all_metadata:\n",
    "        hierarchy_cache[meta[\"CWE_ID\"]] = {\n",
    "            \"abstraction\": meta[\"Abstraction\"],\n",
    "            \"children\": meta[\"Child_IDs\"].split(\",\") if meta.get(\"Child_IDs\") else [],\n",
    "        }\n",
    "    # display(ret_df[ret_df['cve_primary_cwe'].isna()])\n",
    "\n",
    "    def label(desc):\n",
    "        try:\n",
    "            ret = [\n",
    "                x.metadata[\"CWE_ID\"]\n",
    "                for x in hierarchical_retrieval(\n",
    "                    desc,\n",
    "                    vectorstore,\n",
    "                    k_list=k_list,\n",
    "                    hierarchy_cache=hierarchy_cache,\n",
    "                    top_abstraction=top_abstraction,\n",
    "                )\n",
    "            ]\n",
    "            # print(len(ret))\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"General error processing message: {e}\")\n",
    "            return\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        queries = data_df[match_col].tolist()\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                executor.map(label, queries),\n",
    "                total=len(queries),\n",
    "                desc=\"Processing RAG queries\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 4. Create final dataframe\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df[\"rag_candidates\"] = results\n",
    "    ret_df[\"rag_label\"] = ret_df.apply(\n",
    "        lambda row: (\n",
    "            row[\"cve_primary_cwe\"]\n",
    "            if row[\"cve_primary_cwe\"] in row[\"rag_candidates\"]\n",
    "            else (row[\"rag_candidates\"][0] if row[\"rag_candidates\"] else None)\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05efcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_rag_labeled_df = raptor_hierarchy_rag_label(\n",
    "    true_pos_few,\n",
    "    raptor_vectorstore_gpt,\n",
    "    match_col=\"gpt_vulnerability\",\n",
    "    # device=\"cpu\",\n",
    "    k_list=[3, 8, 4, 1, 1],\n",
    "    top_abstraction=CWE_abstraction.PILLAR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a773d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "cl_lengths = [len(cands) for cands in raptor_rag_labeled_df.rag_candidates.to_list()]\n",
    "print(stat.mean(cl_lengths))\n",
    "print(stat.median(cl_lengths))\n",
    "print(max(cl_lengths))\n",
    "print(min(cl_lengths))\n",
    "\n",
    "evaluate_rag(raptor_rag_labeled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75b0c4c",
   "metadata": {},
   "source": [
    "## Reranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9598c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get parent directory (Thesis-Edvin)\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c07d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from rag import *\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from typing import List\n",
    "from openai import OpenAIError, RateLimitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e559c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingScore(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
    "\n",
    "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"vulnerability\", \"doc\"],\n",
    "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the vulnerability. Consider the specific context and intent of the vulnerability, not just keyword matches.\n",
    "        Vulnerability: {vulnerability}\n",
    "        Document: {doc}\n",
    "        Relevance Score:\"\"\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000, api_key=OPENAI_API_KEY_KTH)\n",
    "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
    "    \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"vulnerability\": query, \"doc\": doc.page_content}\n",
    "        try:\n",
    "            score = llm_chain.invoke(input_data).relevance_score\n",
    "        except OpenAIError as e:  # Catch all OpenAI-specific errors\n",
    "            print(f\"OpenAI API error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"General error processing message: {e}\")\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0  # Default score if parsing fails\n",
    "        scored_docs.append((doc, score))\n",
    "    \n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc59cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \n",
    "    vectorstore : FAISS = Field(description=\"Vector store for initial retrieval\")\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
    "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
    "\n",
    "\n",
    "# Create the custom retriever\n",
    "custom_retriever = CustomRetriever(vectorstore=vectorstore_gpt)\n",
    "\n",
    "# Create an LLM for answering questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc35515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=15)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def rerank_rag_label(\n",
    "    data_df, vectorstore, match_col=\"gpt_vulnerability\", k=1, max_workers=15\n",
    "):  # max for k is 20\n",
    "    ret_df = data_df.copy()\n",
    "\n",
    "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "    # display(ret_df[ret_df['cve_primary_cwe'].isna()])\n",
    "    def label(desc):\n",
    "        try:\n",
    "            ret = list(\n",
    "                set([x.metadata[\"CWE_ID\"] for x in custom_retriever._get_relevant_documents(desc, k)])\n",
    "            )\n",
    "            # print(len(ret))\n",
    "            return ret\n",
    "        except Exception as e:\n",
    "            print(f\"General error processing message: {e}\")\n",
    "            return\n",
    "    '''\n",
    "    ret_df[\"rag_candidates\"] = ret_df[match_col].progress_map(lambda x: label(x))\n",
    "    ret_df[\"rag_label\"] = ret_df.apply(\n",
    "        lambda row: (\n",
    "            row[\"cve_primary_cwe\"]\n",
    "            if row[\"cve_primary_cwe\"] in row[\"rag_candidates\"]\n",
    "            else row[\"rag_candidates\"][0]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    '''\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        queries = data_df[match_col].tolist()\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                executor.map(label, queries),\n",
    "                total=len(queries),\n",
    "                desc=\"Processing RAG queries\",\n",
    "            )\n",
    "        )\n",
    "    ret_df = data_df.copy()\n",
    "    ret_df[\"rag_candidates\"] = results\n",
    "    ret_df[\"rag_label\"] = ret_df.apply(\n",
    "        lambda row: (\n",
    "            row[\"cve_primary_cwe\"]\n",
    "            if row[\"cve_primary_cwe\"] in row[\"rag_candidates\"]\n",
    "            else (row[\"rag_candidates\"][0] if row[\"rag_candidates\"] else None)\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_labeled_df = rerank_rag_label(\n",
    "    true_pos_few, vectorstore_gpt, match_col=\"gpt_vulnerability\", k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "\n",
    "cl_lengths = [len(cands) for cands in rag_labeled_df.rag_candidates.to_list()]\n",
    "print(stat.mean(cl_lengths))\n",
    "print(stat.median(cl_lengths))\n",
    "print(max(cl_lengths))\n",
    "print(min(cl_lengths))\n",
    "evaluate_rag(rag_labeled_df, \"rag_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f535da",
   "metadata": {},
   "source": [
    "## Generation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb5bb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get parent directory (Thesis-Edvin)\n",
    "sys.path.append(str(Path.cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c01523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cf66f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "cwes = load_dataset(\"Eathus/cwe_view1000_list_gpt_few_cwe_desc\", split=\"train\")\n",
    "cwe_df = cwes.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_heavy_documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d11bfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from rag import *\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"tmp/view_CWE-1000_all_weaknesses.json\", \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67c38121",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwe_dict = {dat['ID']: dat for dat in data[\"Weaknesses\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46abd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordered_cwe_dict(weakness, doc_density=CWE_doc_density.LIGHT, old=False):\n",
    "    ret =  {\n",
    "        \"ID\": weakness[\"ID\"],\n",
    "        \"Description\": weakness['Description'],\n",
    "        **({\"ExtendedDescription\": weakness['ExtendedDescription']} if \"ExtendedDescription\" in weakness else {}),\n",
    "    }\n",
    "    \n",
    "    if doc_density in [CWE_doc_density.NORM, CWE_doc_density.HEAVY] and \"AlternateTerms\" in weakness :\n",
    "        ret[\"AlternateTerms\"] = weakness[\"AlternateTerms\"]\n",
    "    \n",
    "    if doc_density in [CWE_doc_density.HEAVY] :\n",
    "        if \"CommonConsequences\" in weakness:\n",
    "            ret[\"CommonConsequences\"] = weakness[\"CommonConsequences\"]\n",
    "        if \"AffectedResources\" in weakness:\n",
    "            ret[\"AffectedResources\"] = weakness[\"AffectedResources\"]\n",
    "        if \"ModesOfIntroduction\" in weakness:\n",
    "            ret[\"ModesOfIntroduction\"] = weakness[\"ModesOfIntroduction\"]\n",
    "        if \"BackgroundDetails\" in weakness:\n",
    "            ret[\"BackgroundDetails\"] = weakness[\"BackgroundDetails\"]\n",
    "    \n",
    "\n",
    "    if doc_density in [CWE_doc_density.NORM, CWE_doc_density.HEAVY]:\n",
    "        if \"Notes\" in weakness:\n",
    "            ret[\"Notes\"] = weakness[\"Notes\"]\n",
    "        if \"ObservedExamples\" in weakness:\n",
    "            ret[\"ObservedExamples\"] = [ ex['Description'] for ex in weakness[\"ObservedExamples\"]]        \n",
    "\n",
    "    if \"DemonstrativeExamples\" in weakness:\n",
    "        if doc_density in [CWE_doc_density.LIGHT, CWE_doc_density.NORM] :\n",
    "            ret[\"DemonstrativeExample\"] = weakness['DemonstrativeExamples'][0]\n",
    "        else :\n",
    "            ret[\"DemonstrativeExamples\"] = weakness['DemonstrativeExamples']\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1be91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwe_list_to_json_str(cwes, cwe_dict, indent=4, doc_density=CWE_doc_density.LIGHT):\n",
    "    js_list = [create_ordered_cwe_dict(cwe_dict[cwe], doc_density) for cwe in cwes]\n",
    "    return json.dumps({\"Weaknesses\": js_list}, indent=indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa48def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from utils import *\n",
    "\n",
    "\n",
    "class ReplySchema(BaseModel):\n",
    "    gpt_cwe: str = Field(\n",
    "        description=\"The CWE-ID (*only the number*) of the CWE entry that best fits the vulnerability description\"\n",
    "    )\n",
    "    gpt_cwe_confidence: int = Field(\n",
    "        description=\"An integer from 1 to 5 indicating your level of confidence  (1 = very low, 2 = low, 3 = medium, 4 = high, 5 = very high).\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    api_key=OPENAI_API_KEY_KTH,  # <- this overrides the default\n",
    ")  # maybe set max_token to 14000\n",
    "\n",
    "prompts_dict = load_prompts(os.getcwd() + \"/../utils/prompts\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", prompts_dict[\"RAG_system_setup_json\"]), (\"human\", \"{desc}\")],\n",
    ")\n",
    "\n",
    "\n",
    "def parser(message: ReplySchema):\n",
    "    return message.model_dump_json()\n",
    "\n",
    "\n",
    "llm = llm.with_structured_output(ReplySchema)\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db282219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 15 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from pandarallel import pandarallel\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_exponential,\n",
    "    retry_if_exception_type,\n",
    ")\n",
    "from openai import OpenAIError, RateLimitError  # Explicitly import errors\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=15)\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(5),  # Retry up to 5 times\n",
    "    wait=wait_exponential(multiplier=2, min=1, max=60),  # Exponential backoff\n",
    "    retry=retry_if_exception_type(RateLimitError),  # Retry only on rate limit errors\n",
    ")\n",
    "def _gpt_classify(desc, cwe_entries):\n",
    "    if (\n",
    "        not desc\n",
    "        or not isinstance(desc, str)\n",
    "        or not cwe_entries\n",
    "        or not isinstance(cwe_entries, str)\n",
    "    ):  # Check for empty/invalid messages\n",
    "        return None\n",
    "    return chain.invoke(\n",
    "        {\n",
    "            \"cwe_entries\": cwe_entries,\n",
    "            \"desc\": desc,\n",
    "        }\n",
    "    )  # Adjusted for OpenAI API format\n",
    "\n",
    "\n",
    "def gpt_classify(desc, cwe_entries):\n",
    "    try:\n",
    "        return _gpt_classify(desc, cwe_entries)\n",
    "    except OpenAIError as e:  # Catch all OpenAI-specific errors\n",
    "        print(f\"OpenAI API error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"General error processing message: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1d3efde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file at tmp/rag_cwe_pred.pkl does not exist. Setting gpt_response to 'None'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "file_path = \"tmp/rag_cwe_pred.pkl\"\n",
    "\n",
    "# Define the path to your pickle file\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        rag_labeled_df = pickle.load(file)\n",
    "    print(\"Pickle file loaded successfully!\")\n",
    "else:\n",
    "    print(f\"The file at {file_path} does not exist. Setting gpt_response to 'None'\")\n",
    "    rag_labeled_df[\"rag_prediction\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cbcc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwe_list_to_md_str(cwes, md_documents):\n",
    "    markdown_list = [doc.page_content for doc in md_documents if doc.metadata['CWE_ID'] in cwes]\n",
    "    return \"\\n\".join(markdown_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3833a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_labeled_df.columns)\n",
    "rag_labeled_df.iloc[0].cve_primary_cwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rag = gpt_classify(\n",
    "    rag_labeled_df.iloc[0].gpt_vulnerability,\n",
    "    cwe_list_to_json_str(rag_labeled_df.iloc[0].rag_candidates, cwe_dict, doc_density=CWE_doc_density.HEAVY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97a0aeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean token count:\t\t 16286.786941580756\n",
      "Median token count:\t\t 17716\n",
      "Max token count:\t\t 26983\n",
      "Min token count:\t\t 4204\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "\n",
    "requests = [\n",
    "    [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': prompts_dict[\"RAG_system_setup\"].format(\n",
    "                cwe_entries=cwe_list_to_json_str(row.rag_candidates, cwe_dict, doc_density=CWE_doc_density.HEAVY)\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': row.gpt_vulnerability\n",
    "        }\n",
    "    ]\n",
    "    for _, row in rag_labeled_df[['gpt_vulnerability', 'rag_candidates']].iterrows()\n",
    "]   \n",
    "token_counts = [count_chat_tokens(request) for request in requests]\n",
    "\n",
    "print('Mean token count:\\t\\t', stat.mean(token_counts))\n",
    "print('Median token count:\\t\\t', stat.median(token_counts))\n",
    "print('Max token count:\\t\\t', max(token_counts))\n",
    "print('Min token count:\\t\\t', min(token_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_labeled_df = rag_labeled_df.reset_index(drop=True)\n",
    "display(rag_labeled_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rag_labeled_df.loc[na_indices, [\"gpt_vulnerability\", \"rag_candidates\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "63fae46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6173e72c334dbaa9237785a922f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=20), Label(value='0 / 20'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 1: Processed 291 rows\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "retries = 0\n",
    "max_retries = 10\n",
    "file_path = \"tmp/rag_cwe_pred.pkl\"\n",
    "DELAY = 1\n",
    "# test_df['gpt_response'] = None\n",
    "while (\n",
    "    not rag_labeled_df[rag_labeled_df.rag_prediction.isna()].empty\n",
    "    and retries < max_retries\n",
    "):\n",
    "    # Get indices of rows needing processing\n",
    "    na_indices = rag_labeled_df[\n",
    "        rag_labeled_df.rag_prediction.isna() & ~rag_labeled_df.cve_id.isna()\n",
    "    ].index\n",
    "\n",
    "    if len(na_indices) == 0:\n",
    "        break\n",
    "\n",
    "    # Process ONLY those rows and assign directly to original DF\n",
    "    rag_labeled_df.loc[na_indices, \"rag_prediction\"] = rag_labeled_df.loc[\n",
    "        na_indices, [\"gpt_description\", \"rag_candidates\"]\n",
    "    ].parallel_apply(\n",
    "        lambda x: gpt_classify(\n",
    "            x[\"gpt_description\"], cwe_list_to_json_str(x[\"rag_candidates\"], cwe_dict, doc_density=CWE_doc_density.HEAVY)\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    with open(file_path, \"wb\") as file:  # 'wb' mode writes in binary format\n",
    "        pickle.dump(rag_labeled_df, file)\n",
    "    retries += 1\n",
    "    print(f\"Retry {retries}: Processed {len(na_indices)} rows\")\n",
    "    time.sleep(DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5911b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_labeled_df.rag_prediction.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3136389f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        {'gpt_cwe': '415', 'gpt_cwe_confidence': 5}\n",
       "5       {'gpt_cwe': '1392', 'gpt_cwe_confidence': 5}\n",
       "11       {'gpt_cwe': '122', 'gpt_cwe_confidence': 5}\n",
       "14        {'gpt_cwe': '89', 'gpt_cwe_confidence': 5}\n",
       "16       {'gpt_cwe': '913', 'gpt_cwe_confidence': 5}\n",
       "                            ...                     \n",
       "1752     {'gpt_cwe': '122', 'gpt_cwe_confidence': 5}\n",
       "1756     {'gpt_cwe': '754', 'gpt_cwe_confidence': 4}\n",
       "1763      {'gpt_cwe': '20', 'gpt_cwe_confidence': 5}\n",
       "1770     {'gpt_cwe': '648', 'gpt_cwe_confidence': 4}\n",
       "1773      {'gpt_cwe': '79', 'gpt_cwe_confidence': 5}\n",
       "Name: rag_prediction, Length: 291, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_labeled_df['rag_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0de5c5ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m rag_labeled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrag_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrag_labeled_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrag_prediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/pandas/core/series.py:4700\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4621\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4622\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4623\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4624\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4626\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4627\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4698\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4700\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4702\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4703\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[102], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m rag_labeled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrag_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rag_labeled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrag_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/mthesis_cpyenv/lib/python3.10/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "rag_labeled_df['rag_prediction'] = rag_labeled_df['rag_prediction'].map(\n",
    "    lambda x: json.loads(x) if pd.notna(x) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c2c630b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rag_prediction</th>\n",
       "      <th>rag_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1392</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>913</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rag_prediction  rag_confidence\n",
       "4             415               5\n",
       "5            1392               5\n",
       "11            122               5\n",
       "14             89               5\n",
       "16            913               5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = rag_labeled_df.copy()\n",
    "test_df[['rag_prediction', 'rag_confidence']] = test_df['rag_prediction'].apply(\n",
    "    lambda x: pd.Series({\"1\":x['gpt_cwe'], \"2\":x['gpt_cwe_confidence']}) if pd.notna(x) else None\n",
    ")\n",
    "test_df[[\"rag_prediction\", \"rag_confidence\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29efc235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5051546391752577\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1050       0.00      0.00      0.00         1\n",
      "        1067       0.00      0.00      0.00         0\n",
      "         116       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         7\n",
      "         120       0.50      0.43      0.46        14\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       0.03      1.00      0.05         1\n",
      "         125       1.00      0.12      0.21        17\n",
      "         129       0.00      0.00      0.00         0\n",
      "        1333       1.00      1.00      1.00         1\n",
      "        1335       0.00      0.00      0.00         0\n",
      "        1392       0.00      0.00      0.00         0\n",
      "         150       1.00      1.00      1.00         1\n",
      "         190       0.75      0.75      0.75         4\n",
      "          20       0.25      0.33      0.29         3\n",
      "         200       0.00      0.00      0.00         1\n",
      "         212       1.00      1.00      1.00         1\n",
      "          22       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         0\n",
      "         280       0.00      0.00      0.00         1\n",
      "         283       0.00      0.00      0.00         1\n",
      "         284       0.00      0.00      0.00         0\n",
      "         290       0.00      0.00      0.00         0\n",
      "         295       0.00      0.00      0.00         1\n",
      "         297       0.00      0.00      0.00         0\n",
      "         300       0.00      0.00      0.00         0\n",
      "         306       1.00      1.00      1.00         1\n",
      "         369       0.50      1.00      0.67         1\n",
      "          37       0.00      0.00      0.00         0\n",
      "         372       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         2\n",
      "         401       0.89      0.94      0.92        18\n",
      "         407       0.33      1.00      0.50         1\n",
      "         410       0.00      0.00      0.00         0\n",
      "         415       1.00      1.00      1.00         3\n",
      "         416       0.69      0.90      0.78        10\n",
      "         424       0.00      0.00      0.00         0\n",
      "         434       1.00      0.50      0.67         2\n",
      "         476       0.91      0.88      0.89        56\n",
      "         497       0.00      0.00      0.00         0\n",
      "         532       1.00      1.00      1.00         3\n",
      "         590       0.00      0.00      0.00         0\n",
      "         601       1.00      1.00      1.00         1\n",
      "         617       0.93      0.93      0.93        15\n",
      "         648       0.00      0.00      0.00         0\n",
      "         665       0.00      0.00      0.00         1\n",
      "         674       0.00      0.00      0.00         0\n",
      "         681       0.00      0.00      0.00         0\n",
      "         690       0.00      0.00      0.00         0\n",
      "         703       0.00      0.00      0.00         0\n",
      "         704       0.00      0.00      0.00         1\n",
      "         732       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         2\n",
      "         754       0.00      0.00      0.00         1\n",
      "         755       0.00      0.00      0.00         0\n",
      "         762       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         1\n",
      "         770       0.00      0.00      0.00        14\n",
      "          78       0.33      1.00      0.50         2\n",
      "         787       0.50      0.05      0.10        56\n",
      "         789       0.00      0.00      0.00         0\n",
      "          79       1.00      1.00      1.00         8\n",
      "         798       0.00      0.00      0.00         2\n",
      "         822       0.00      0.00      0.00         0\n",
      "         824       0.00      0.00      0.00         0\n",
      "         862       0.00      0.00      0.00         1\n",
      "          89       1.00      0.62      0.76        26\n",
      "         913       0.00      0.00      0.00         0\n",
      "         918       1.00      1.00      1.00         1\n",
      "          94       1.00      0.33      0.50         3\n",
      "          95       0.00      0.00      0.00         0\n",
      "        None       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       291\n",
      "   macro avg       0.27      0.27      0.25       291\n",
      "weighted avg       0.67      0.51      0.52       291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/edvinn/anaconda3/envs/mthesis_cpyenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_rag(test_df, \"rag_prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mthesis_cpyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
